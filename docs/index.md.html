**Scientific cluster**

Introduction
============

`Scientific cluster` provides a virtual simulation on a cluster based on
[LUSTRE](http://lustre.org) (a open-source parallel file system used in HPC) and [SLURM](https://slurm.schedmd.com) (a open-source fault-tolerant cluster
management system). This is arguably the most common architecture used in
scientific computer clusters.

The virtual simulation runs on top of [QEMU](http://www.qemu.org).

The main purpose of this package is to allow administrators of scientific
clusters to test different configurations before deployment.

In the near future we will also support [Singularity](http://singularity.lbl.gov/index.html) (A user managed container system allowing the deployment of
complex workloads on a cluster).

There might be other components included (for example, OpenLDAP and NFS).

Requirements
============

- An OS that can run QEMU. This was tested on Linux as a host
  environment.  We suspect that it will almost "out of the box" on a
  Mac and it will need some work on Windows
- QEMU
- 12 GB of memory
- sshpass
- bash
- ~30 GB of free disk space
- root access

Optional (but strongly recommended):

- VNC client

Example Architecture
======================

![Cluster architecture](cluster.png)

!!! Note to self
    Explain the architecture


!!! WARNING
    The current architecture does not follow best practices.
    As you can see there are cases that have both server and clients
    of LUSTRE. Users can put jobs on LUSTRE and SLURM master nodes.
    This is one example of architecture. You can use this framework
    to test your architectures.

This will include the following machines (host names given as definition)



## General admin

ldap
:   A support machine with a LDAP server for user account information.

DHCP will be supplied by QEMU as configured by us.

Name resolution will be hard-coded in all machines' `/etc/hosts`
files.

## Core

head
:   User/SLURM Head node with LUSTRE Client

slurm-master
:   SLURM master **and SLURM compute**. LUSTRE client

lustre-meta
:   LUSTRE meta master ***and client***. SLURM compute

lustre-object
:   LUSTRE object master ***and client***. SLURM compute

standard-client
:   LUSTRE client, SLURM compute

nfs
:   NFS export with LUSTRE client

## Researcher


pi-head
:  SLURM head node for the PI. NFS import. LDAP client?

pi-compute
:  SLURM compute. LUSTRE compute. With prioritizing rule for PI.

!!! Note to self
    User sync between `pi-head` and cluster to be addressed.

Installation
=============


!!! WARNING
    Make sure you read the Architecture section above before
    proceeding. It includes all the machine names and descriptions
    that we will be creating.

!!!
    All work that you need todo will be preceded box like this. The
    rest is explanation.

!!! WARNING
    Sometimes the VNC interface will be empty. The underlying
    machine is most probably working.  You only _really_ need the
    interface to make the base image, but if you want to be sure,
    restart the machine until you get VNC.

!!! WARNING
    XXX Discuss assumption of DHCP address allocation


## Creation of a base image


### Basic image initialization

The first issue is the creation of a base image that will be used to
create all other images:

The steps are:

- Download the ISO for Ubuntu Server 16.04
- Patch the ISO to auto-install
- Create a virtual disk
- Run the patched ISO to create the base image

!!!
    Run a script and connect to VNC

`bash scripts/create_base_image.sh`

Note that it will create a
**password-less** VNC interface on *:1 .

This will take a lot of time to run. Connect to the VNC interface as
soon as it is up to monitor the progress. Kill the script as soon as there
machine reboots, after clicking continue here:

![Install finish](install_finish.png)

Wait for the machine to reboot and kill QEMU (do not let it boot).

The machine has SSH and the root password is test. We will take care of
security in step 2.

### Securing and backing up the base image

Now you have `pre-base.img`.


!!!
    Copy a image file

`cp pre-base.img base.img
cp pre-base.img backup.img`

Copy this to `base.img` and `backup.img`.
The backup image will be useful if you have problems from now on.

The base image will be patched to allow public/private key login instead of
password.

!!!
    Start the base image with

```bash
qemu-system-x86_64 -m 1G -drive file=base.img,format=raw -vnc :1 \
  -net nic,macaddr=52:54:00:12:34:56 -net socket,listen=:1234 \
  -net user,hostfwd=tcp:127.0.0.1:22222-:22
```

Monitor by connecting to the VNC interface.

!!!
    Test the ssh login
    
`ssh -p22222 root@localhost`

The password is `test`. Note that the VM might take some time to start
(monitor its progress with VNC).

!!!
    Put your public key in the current directory

This will be `id_rsa.pub` or `id_dsa.pub`.

!!!
    Upload the public key

`bash scripts/prepare_security.sh`.

You will need tp input the password a couple of times.

Give it some time to halt (or check on VNC). Shutdown QEMU.

!!! WARNING
    Security here is nothing special.
    This is for testing and prototyping configurations, not production

### Basic networking

Here we will configure the base image to accept DHCP hostnames and
add a `/etc/hosts` file with all host names preloaded.

But first we will copy an image that will be the DHCP server

!!!
    Copy a image for DHCP configuration _later_

`cp base.img dhcp.img`

!!!
    Start the base image with

```bash
qemu-system-x86_64 -m 1G -drive file=base.img,format=raw -vnc :1 \
  -net nic,macaddr=52:54:00:12:34:56 -net socket,listen=:1234 \
  -net user,hostfwd=tcp:127.0.0.1:22222-:22
```

Make sure it is up.

!!!
   Run a script to prepare the networking
   
`bash scripts/prepare_networking.sh`

Give it some time to halt (or check on VNC). Shutdown QEMU.


### Sanity checking and backup

!!!
    Start the machine again

```bash
qemu-system-x86_64 -m 1G -drive file=base.img,format=raw -vnc :1 \
  -net nic,macaddr=52:54:00:12:34:56 -net socket,listen=:1234 \
  -net user,hostfwd=tcp:127.0.0.1:22222-:22,hostname=base.cluster
```

!!!
    Login and check if all is OK

`ssh -p22222 root@localhost`

- **No password** should be requested
- On the prompt the machine should be called base
- `hostname` should return `base.cluster`
- `cat /etc/hosts | grep 2.15` should report a ldap name
  The login will report `base` as host


!!!
    Halt and shutdown
	
As with previous shutdown cases, make sure the machine really shuts
down before killing QEMU.


## Creation of a DHCP and LDAP server

DHCP and LDAP servers will be on the same machine `dhcp.img`

!!!
    You might want to backup `dhcp.img`

`cp dhcp.img dhcp-backup.img`


!!!
    Start the DHCP/LDAP machine

```bash
qemu-system-x86_64 -m 1G -drive file=dhcp.img,format=raw -vnc :1 \
  -net nic,macaddr=52:54:00:12:34:56 -net socket,listen=:1234  \
  -net user,hostfwd=tcp:127.0.0.1:22222-:22,hostname=ldap.cluster
```


## Other stuff

singularity

(add conda also?)

Making your configurations
=============================


FAQ
===

## Why not Docker?

LUSTRE requires access to block volumes.

## Why not KVM (Kernel-based Virtual Machine)?

It should be easy to alter the QEMU commands (`-enable-kvm`) for this.
But, to ensure compatibility on Windows and Mac, this is not active.


Contact
=======


<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>

<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js"></script>

<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
